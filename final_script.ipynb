{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bd_conn_config(table):\n",
    "    user = \"mpllv\"\n",
    "    host = f\"localhost/{table}\"\n",
    "    return f\"postgresql+psycopg://{user}@{host}\"\n",
    "\n",
    "def get_data(conn, query):\n",
    "    result = conn.execute(text(query))\n",
    "\n",
    "    result_dict = result.mappings().all() \n",
    "\n",
    "    if len(result_dict) >= 1:\n",
    "        organized_result = {key: [dict[key] for dict in result_dict] for key in result_dict[0]}\n",
    "        return organized_result\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "def get_data_params(conn, query, params):\n",
    "    result = conn.execute(text(query), params)\n",
    "\n",
    "    result_dict = result.mappings().all() \n",
    "\n",
    "    if len(result_dict) >= 1:\n",
    "        organized_result = {key: [dict[key] for dict in result_dict] for key in result_dict[0]}\n",
    "        return organized_result\n",
    "    else: \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(bd_conn_config('paipe-test'))\n",
    "conn = engine.connect()\n",
    "\n",
    "query_train = 'select * from train_houses'\n",
    "query_test = 'select * from test_houses'\n",
    "\n",
    "train_df = pl.DataFrame(get_data(conn, query_train)).with_columns(\n",
    "    pl.col('MinTimeToNearestStation').cast(pl.Int64), pl.col('MaxTimeToNearestStation').cast(pl.Int64),\n",
    "    pl.col('TotalFloorArea').cast(pl.Int64), pl.col('BuildingYear').cast(pl.Int64), \n",
    "    pl.col('CoverageRatio').cast(pl.Int64), pl.col('FloorAreaRatio').cast(pl.Int64)\n",
    ")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação e limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script para verificação das colunas a serem retiradas\n",
    "# Retirar colunas com > 30% dos valores nulos\n",
    "summary_train = train_df.describe()\n",
    "\n",
    "data_size = len(train_df)\n",
    "\n",
    "trim_row = []\n",
    "trim_column = []\n",
    "\n",
    "columns = summary_train.columns\n",
    "columns.remove('statistic')\n",
    "columns\n",
    "\n",
    "for column in columns:\n",
    "    nulls = int(summary_train[1, column])\n",
    "\n",
    "    if nulls > (data_size * 0.3):\n",
    "        trim_column.append(column)\n",
    "\n",
    "print('columns to trim: ', trim_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação dos tipos de propriedade\n",
    "train_df.select('Region').group_by('Region').len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_column.remove('TotalFloorArea')\n",
    "trim_column.remove('Frontage')\n",
    "trim_column.remove('Region')\n",
    "trim_column.remove('UnitPrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somente se enquadram colunas no critério dos 30%\n",
    "train_df = train_df.drop(trim_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchimento de valores nulos em colunas que é possível substituir por 0\n",
    "train_df = train_df.with_columns(\n",
    "    pl.col('CoverageRatio').fill_null(0),\n",
    "    pl.col('FloorAreaRatio').fill_null(0),\n",
    "    pl.col('TotalFloorArea').fill_null(0),\n",
    "    pl.col('Frontage').fill_null(0)\n",
    ")\n",
    "\n",
    "# Prenchimento dos valores nulos da coluna UnitPrice por -1\n",
    "train_df = train_df.with_columns(\n",
    "    pl.col('UnitPrice').fill_null(-1)\n",
    ")\n",
    "\n",
    "# Preenchimento dos valores nulos na coluna \"CityPlanning\" e \"Region\" por 'Other'\n",
    "train_df = train_df.with_columns(pl.col('CityPlanning').fill_null('Other'),\n",
    "                                 pl.col('Region').fill_null('Other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot inicial para análise de outliers\n",
    "fig = px.box(train_df.to_pandas(), x = 'TradePrice')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica-se que o limite superior do boxplot é 100M e representam menos de 10% dos dados\n",
    "len(train_df.filter(pl.col('TradePrice') > 100000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retira-se os outliers\n",
    "train_df = train_df.filter(pl.col('TradePrice') <= 100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituição do trimestre pelo semestre e transformação da variável year em categórica\n",
    "train_df = train_df.with_columns(pl.col('Quarter').cast(pl.String).str.replace_all('2', '1').str.replace_all(\n",
    "    '4', '2').str.replace_all('3', '2'), \n",
    "    pl.col('Year').cast(pl.String)).rename({'Quarter': 'Semester'})\n",
    "\n",
    "# A variável Year e Semester podem ser agrupadas e substituir a Period\n",
    "train_df = train_df.replace_column(-4, train_df.with_columns(\n",
    "    pl.concat_str([pl.col('Year'), pl.col('Semester')], separator='_').alias('YearSemester')\n",
    "    ).select('YearSemester').to_series(0)).drop(['Year', 'Semester'])\n",
    "\n",
    "# A variável TimeToNearestStation é categórica, mas pode ser substituída pela média do Min e Max\n",
    "train_df = train_df.replace_column(7, train_df.with_columns(\n",
    "    mean_time=pl.mean_horizontal(\"MinTimeToNearestStation\", \"MaxTimeToNearestStation\").cast(pl.Int64).cast(pl.String)\n",
    "    ).select('mean_time').rename(\n",
    "    {'mean_time': 'TimeToNearestStation'}).to_series(0)\n",
    "    ).with_columns(\n",
    "    pl.col('TimeToNearestStation').cast(pl.Int64)\n",
    "    ).drop(['MinTimeToNearestStation', 'MaxTimeToNearestStation'])\n",
    "\n",
    "# Todas as observações são da Prefecture \"Tokyo\" e a MunicipalityCode já é representada pela Municipality\n",
    "train_df = train_df.drop(['MunicipalityCode', 'Prefecture'])\n",
    "\n",
    "# As colunas BuildingYear, Structure e Use ainda possuem um grande número de valores nulos\n",
    "train_df = train_df.drop(['BuildingYear', 'Structure', 'Use'])\n",
    "\n",
    "# Substituição das linhas sem informação na coluna DistrictName por Other\n",
    "train_df = train_df.with_columns(pl.col('DistrictName').str.replace_all('(No Address)', \n",
    "                                 'Other', literal = True).fill_null('Other'))\n",
    "\n",
    "# Tranformação da coluna FrontageIsGreaterFlag\n",
    "train_df = train_df.with_columns(pl.col('FrontageIsGreaterFlag').cast(pl.String).str.replace_all(\n",
    "    'false', '0').str.replace_all('true', '1').cast(pl.Int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário das colunas com valores nulos restantes\n",
    "remaining_null_columns = []\n",
    "for item in train_df.describe().columns:\n",
    "    if item != 'statistic':\n",
    "        if int(train_df.describe()[1, item]) > 0:\n",
    "            remaining_null_columns.append(item)\n",
    "remaining_null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.select(\n",
    "    ['DistrictName', 'Type', 'NearestStation']).group_by(['DistrictName', 'Type']).max().filter(pl.col('NearestStation').is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição de uma coluna de índice para facilitar a etapa seguinte\n",
    "train_df.insert_column(0, pl.Series('index', list(range(len(train_df)))))\n",
    "\n",
    "# Preenchimento dos valores faltantes com base em diferentes estratégias de acordo com a variável\n",
    "\n",
    "# NearestStation: mais frequente dentre o distrito e tipo de propriedade\n",
    "station_filler = train_df.select(\n",
    "    ['DistrictName', 'Type', 'NearestStation']).group_by(\n",
    "    ['DistrictName', 'Type']).max().filter(pl.col('NearestStation').is_not_null())\n",
    "\n",
    "missing_stations = list(train_df.filter(pl.col('NearestStation').is_null())['index'])\n",
    "\n",
    "for index in missing_stations:\n",
    "    temp = train_df[index]\n",
    "    filler = station_filler.filter((pl.col('DistrictName') == temp[0, 'DistrictName']) & \n",
    "                                        (pl.col('Type') == temp[0, 'Type']))\n",
    "    if len(filler) > 0:\n",
    "        train_df[index, 'NearestStation'] = filler[0, 'NearestStation']\n",
    "    else:\n",
    "        train_df[index, 'NearestStation'] = temp[0, 'DistrictName']\n",
    "\n",
    "# TimeToNearestStation: média das propriedades com a mesma estação mais próxima\n",
    "timeStation_filler = train_df.select(['DistrictName', 'NearestStation', 'TimeToNearestStation']).group_by(\n",
    "    'DistrictName', 'NearestStation').mean().with_columns(pl.col('TimeToNearestStation').cast(pl.Int64))\n",
    "\n",
    "missing_timeStation = list(train_df.filter(pl.col('TimeToNearestStation').is_null())['index'])\n",
    "\n",
    "for index in missing_timeStation:\n",
    "    temp = train_df[index]\n",
    "    filler = timeStation_filler.filter(\n",
    "            pl.col('NearestStation') == temp[0, 'NearestStation'])[0, 'TimeToNearestStation']\n",
    "    train_df[index, 'TimeToNearestStation'] = filler\n",
    "\n",
    "# Subsituição dos valores nulos em TimeToNearestStation por -1\n",
    "train_df = train_df.with_columns(pl.col('TimeToNearestStation').fill_null(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sem valores nulos restantes\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando colunas que não serão utilizadas na regressão\n",
    "train_df = train_df.drop(['DistrictName', 'NearestStation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = train_df.drop('index').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(pd_train, x = 'TradePrice')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(pd_train, x = 'Type', y = 'TradePrice', color = 'Type')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_train = pd_train.drop(columns = ['Type', 'Region',  'Municipality', 'CityPlanning', 'YearSemester']).corr()\n",
    "fig = px.imshow(corr_train, x = corr_train.columns, y = corr_train.index, text_auto=True, aspect=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prep_train = pd_train.iloc[:, :-1]\n",
    "y_train = pd_train.iloc[:, -1].values\n",
    "\n",
    "# Conversão das variáveis categóricas em dummies\n",
    "x_train = pd.get_dummies(x_prep_train, \n",
    "                         columns=['Type','Region', 'Municipality', 'CityPlanning', 'YearSemester'], dtype=int).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'n_estimators': [150, 175, 200, 225, 250, 275, 300],\n",
    "               'criterion': ['squared_error'], \n",
    "               'min_samples_split': [5, 10, 15, 20, 25], \n",
    "               'max_features': ['sqrt', 'log2'], \n",
    "               'bootstrap': [True, False],\n",
    "               'oob_score': [True, False]}\n",
    "\n",
    "rfr = GridSearchCV(estimator=RandomForestRegressor(random_state=123), param_grid=grid_params, n_jobs=8, \n",
    "                   cv=2, verbose=2)\n",
    "rfr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(x_train)\n",
    "\n",
    "print('Best parameters: ', rfr.best_params_)\n",
    "print('Best score: ', rfr.best_score_)\n",
    "print('RMSLE: ', metrics.root_mean_squared_log_error(y_train, y_pred))\n",
    "print('MAPE: ', metrics.mean_absolute_percentage_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aplicação do modelo aos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(bd_conn_config('paipe-test'))\n",
    "conn = engine.connect()\n",
    "\n",
    "query_train = 'select * from train_houses'\n",
    "query_test = 'select * from test_houses'\n",
    "\n",
    "test_df = pl.DataFrame(get_data(conn, query_test)).with_columns(\n",
    "    pl.col('MinTimeToNearestStation').cast(pl.Int64), pl.col('MaxTimeToNearestStation').cast(pl.Int64),\n",
    "    pl.col('TotalFloorArea').cast(pl.Int64), pl.col('BuildingYear').cast(pl.Int64), \n",
    "    pl.col('CoverageRatio').cast(pl.Int64), pl.col('FloorAreaRatio').cast(pl.Int64)\n",
    ")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados de teste com a mesma metodologia utilizada nos dados de treino\n",
    "\n",
    "test_df = test_df.drop(trim_column).with_columns(\n",
    "    pl.col('CoverageRatio').fill_null(0),\n",
    "    pl.col('FloorAreaRatio').fill_null(0),\n",
    "    pl.col('TotalFloorArea').fill_null(0),\n",
    "    pl.col('Frontage').fill_null(0)\n",
    "    ).with_columns(\n",
    "    pl.col('UnitPrice').fill_null(-1)\n",
    "    ).with_columns(\n",
    "        pl.col('CityPlanning').fill_null('Other'),\n",
    "        pl.col('Region').fill_null('Other'))\n",
    "\n",
    "test_df = test_df.with_columns(pl.col('Quarter').cast(pl.String).str.replace_all('2', '1').str.replace_all(\n",
    "    '4', '2').str.replace_all('3', '2'), \n",
    "    pl.col('Year').cast(pl.String)).rename({'Quarter': 'Semester'})\n",
    "\n",
    "test_df = test_df.replace_column(-4, test_df.with_columns(\n",
    "    pl.concat_str([pl.col('Year'), pl.col('Semester')], separator='_').alias('YearSemester')\n",
    "    ).select('YearSemester').to_series(0)).drop(['Year', 'Semester'])\n",
    "\n",
    "test_df = test_df.replace_column(7, test_df.with_columns(\n",
    "    mean_time=pl.mean_horizontal(\"MinTimeToNearestStation\", \"MaxTimeToNearestStation\").cast(pl.Int64).cast(pl.String)\n",
    "    ).select('mean_time').rename(\n",
    "    {'mean_time': 'TimeToNearestStation'}).to_series(0)\n",
    "    ).with_columns(\n",
    "    pl.col('TimeToNearestStation').cast(pl.Int64)\n",
    "    ).drop(['MinTimeToNearestStation', 'MaxTimeToNearestStation'])\n",
    "\n",
    "test_df = test_df.drop(['MunicipalityCode', 'Prefecture','BuildingYear', 'Structure', 'Use'])\n",
    "\n",
    "test_df = test_df.with_columns(pl.col('DistrictName').str.replace_all('(No Address)', \n",
    "        'Other', literal = True).fill_null('Other'))\n",
    "\n",
    "test_df = test_df.with_columns(\n",
    "        pl.col('FrontageIsGreaterFlag').cast(pl.String).str.replace_all(\n",
    "        'false', '0').str.replace_all('true', '1').cast(pl.Int64)\n",
    "    )\n",
    "\n",
    "test_df.insert_column(0, pl.Series('index', list(range(len(test_df)))))\n",
    "\n",
    "missing_stations = list(test_df.filter(pl.col('NearestStation').is_null())['index'])\n",
    "for index in missing_stations:\n",
    "    temp = test_df[index]\n",
    "    filler = station_filler.filter((pl.col('DistrictName') == temp[0, 'DistrictName']) & \n",
    "                                        (pl.col('Type') == temp[0, 'Type']))\n",
    "    if len(filler) > 0:\n",
    "        test_df[index, 'NearestStation'] = filler[0, 'NearestStation']\n",
    "    else:\n",
    "        test_df[index, 'NearestStation'] = temp[0, 'DistrictName']\n",
    "\n",
    "missing_timeStation = list(test_df.filter(pl.col('TimeToNearestStation').is_null())['index'])\n",
    "for index in missing_timeStation:\n",
    "    temp = test_df[index]\n",
    "    filler = timeStation_filler.filter(\n",
    "            pl.col('NearestStation') == temp[0, 'NearestStation'])[0, 'TimeToNearestStation']\n",
    "    test_df[index, 'TimeToNearestStation'] = filler\n",
    "\n",
    "test_df = test_df.with_columns(pl.col('TimeToNearestStation').fill_null(-1)\n",
    "                                 ).drop(['DistrictName', 'NearestStation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test = test_df.drop('index').to_pandas()\n",
    "x_prep_test = pd_test.iloc[:, :-1]\n",
    "x_test = pd.get_dummies(x_prep_test, columns=['Type', 'Region', 'Municipality', 'CityPlanning', 'YearSemester'], dtype=int).values\n",
    "y_test = rfr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test['TradePrice'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_train = train_df.drop('index').hstack([pl.Series('Origin', ['Train'] * len(train_df))])\n",
    "\n",
    "final_df_test = pl.from_pandas(pd_test)\n",
    "final_df_test = final_df_test.hstack([pl.Series('Origin', ['Test'] * len(final_df_test))])\n",
    "\n",
    "combined = final_df_test.with_columns(pl.col('TradePrice').cast(pl.Int64)).vstack(final_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = final_df_test.with_columns(pl.col('TradePrice').cast(pl.Int64)).vstack(final_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(combined.to_pandas(), x = 'Type', y = 'TradePrice', color = 'Origin')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_test.write_csv('test_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
